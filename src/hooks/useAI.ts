import { aiConversationApi } from '@/api/ai'
import { supabase } from '@/api/supabase'
import { AIAssistantConfig, AIConversation, AIMessage } from '@/types'
import { AI_MODES, getAIConfigDescription, validateAIConfig } from '@/utils/ai'
import { useCallback, useEffect, useState } from 'react'

// ğŸš€ é™æ€å¯¼å…¥AIæœåŠ¡ï¼Œæ¶ˆé™¤åŠ¨æ€å¯¼å…¥å»¶è¿Ÿ
import { aiService } from '@/api/ai'

export const useAI = () => {
  const [conversations, setConversations] = useState<AIConversation[]>([])
  const [currentConversation, setCurrentConversation] = useState<AIConversation | null>(null)
  const [messages, setMessages] = useState<AIMessage[]>([])
  const [loading, setLoading] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const [aiConfig, setAIConfig] = useState<AIAssistantConfig>({
    mode: 'bullet_tutor',
    model: 'gpt-3.5-turbo' // é»˜è®¤ä½¿ç”¨GPT-3.5-turbo
  })

  // è·å–ç”¨æˆ·çš„æ‰€æœ‰å¯¹è¯
  const fetchConversations = useCallback(async () => {
    setLoading(true)
    setError(null)
    
    try {
      const response = await aiConversationApi.getUserConversations()
      if (response.error) {
        setError(response.error)
      } else {
        setConversations(response.data)
      }
    } catch (err: any) {
      setError(err.message)
    } finally {
      setLoading(false)
    }
  }, [])

  // åˆ›å»ºæ–°å¯¹è¯
  const createConversation = useCallback(async (
    assistantType: AIConversation['assistant_type'],
    taskId?: string
  ) => {
    setLoading(true)
    setError(null)
    
    try {
      const response = await aiConversationApi.createConversation(assistantType, taskId)
      if (response.error) {
        setError(response.error)
        return null
      } else {
        const newConversation = response.data
        setConversations(prev => [newConversation, ...prev])
        setCurrentConversation(newConversation)
        setMessages([])
        return newConversation
      }
    } catch (err: any) {
      setError(err.message)
      return null
    } finally {
      setLoading(false)
    }
  }, [])

  // é€‰æ‹©å¯¹è¯
  const selectConversation = useCallback(async (conversationId: string) => {
    setLoading(true)
    setError(null)
    
    try {
      const conversation = conversations.find(c => c.id === conversationId)
      if (!conversation) {
        setError('Conversation does not exist')
        return
      }

      setCurrentConversation(conversation)
      
      // è·å–å¯¹è¯æ¶ˆæ¯
      const response = await aiConversationApi.getConversationMessages(conversationId)
      if (response.error) {
        setError(response.error)
      } else {
        setMessages(response.data)
      }
    } catch (err: any) {
      setError(err.message)
    } finally {
      setLoading(false)
    }
  }, [conversations])

  // åˆ é™¤å¯¹è¯ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæ”¯æŒä¹è§‚æ›´æ–°
  const deleteConversation = useCallback(async (conversationId: string) => {
    // ğŸš€ ä¹è§‚æ›´æ–°ï¼šç«‹å³æ›´æ–°UIï¼Œç»™ç”¨æˆ·ç¬é—´åé¦ˆ
    const originalConversations = conversations
    const originalCurrentConversation = currentConversation
    const originalMessages = messages

    // ç«‹å³ä»æœ¬åœ°çŠ¶æ€ä¸­ç§»é™¤å¯¹è¯
    setConversations(prev => prev.filter(conv => conv.id !== conversationId))
    
    // å¦‚æœåˆ é™¤çš„æ˜¯å½“å‰å¯¹è¯ï¼Œç«‹å³æ¸…ç©ºå½“å‰å¯¹è¯
    if (currentConversation?.id === conversationId) {
      setCurrentConversation(null)
      setMessages([])
    }

    console.log('ğŸ—‘ï¸ ä¹è§‚åˆ é™¤ï¼šUIå·²ç«‹å³æ›´æ–°')

    try {
      // ğŸš€ åå°å¼‚æ­¥æ‰§è¡Œå®é™…åˆ é™¤æ“ä½œ
      const response = await aiConversationApi.deleteConversation(conversationId)
      
      if (response.error) {
        // âŒ åˆ é™¤å¤±è´¥ï¼Œå›æ»šUIçŠ¶æ€
        console.error('âŒ åˆ é™¤å¤±è´¥ï¼Œå›æ»šçŠ¶æ€:', response.error)
        setConversations(originalConversations)
        setCurrentConversation(originalCurrentConversation)
        setMessages(originalMessages)
        setError(`åˆ é™¤å¤±è´¥: ${response.error}`)
        return { success: false, error: response.error }
      }

      console.log('âœ… åå°åˆ é™¤æˆåŠŸç¡®è®¤')
      return { success: true }
    } catch (err: any) {
      // âŒ ç½‘ç»œé”™è¯¯ï¼Œå›æ»šUIçŠ¶æ€
      console.error('âŒ ç½‘ç»œé”™è¯¯ï¼Œå›æ»šçŠ¶æ€:', err.message)
      setConversations(originalConversations)
      setCurrentConversation(originalCurrentConversation)
      setMessages(originalMessages)
      setError(`åˆ é™¤å¤±è´¥: ${err.message}`)
      return { success: false, error: err.message }
    }
  }, [conversations, currentConversation, messages])

  // åˆ é™¤æ‰€æœ‰å¯¹è¯ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæ”¯æŒä¹è§‚æ›´æ–°
  const deleteAllConversations = useCallback(async () => {
    if (conversations.length === 0) {
      return { success: true, deletedCount: 0 }
    }

    // ğŸš€ ä¹è§‚æ›´æ–°ï¼šç«‹å³æ¸…ç©ºUI
    const originalConversations = conversations
    const originalCurrentConversation = currentConversation
    const originalMessages = messages
    const deletedCount = conversations.length

    // ç«‹å³æ¸…ç©ºæœ¬åœ°çŠ¶æ€
    setConversations([])
    setCurrentConversation(null)
    setMessages([])

    console.log(`ğŸ—‘ï¸ ä¹è§‚åˆ é™¤ï¼š${deletedCount}ä¸ªå¯¹è¯å·²ç«‹å³æ¸…ç©º`)

    try {
      // ğŸš€ åå°å¼‚æ­¥æ‰§è¡Œå®é™…åˆ é™¤æ“ä½œ
      const response = await aiConversationApi.deleteAllConversations()
      
      if (response.error) {
        // âŒ åˆ é™¤å¤±è´¥ï¼Œå›æ»šUIçŠ¶æ€
        console.error('âŒ æ‰¹é‡åˆ é™¤å¤±è´¥ï¼Œå›æ»šçŠ¶æ€:', response.error)
        setConversations(originalConversations)
        setCurrentConversation(originalCurrentConversation)
        setMessages(originalMessages)
        setError(`æ‰¹é‡åˆ é™¤å¤±è´¥: ${response.error}`)
        return { success: false, error: response.error }
      }

      console.log(`âœ… åå°æ‰¹é‡åˆ é™¤æˆåŠŸç¡®è®¤: ${response.data.deletedCount}ä¸ªå¯¹è¯`)
      return { success: true, deletedCount: response.data.deletedCount }
    } catch (err: any) {
      // âŒ ç½‘ç»œé”™è¯¯ï¼Œå›æ»šUIçŠ¶æ€
      console.error('âŒ æ‰¹é‡åˆ é™¤ç½‘ç»œé”™è¯¯ï¼Œå›æ»šçŠ¶æ€:', err.message)
      setConversations(originalConversations)
      setCurrentConversation(originalCurrentConversation)
      setMessages(originalMessages)
      setError(`æ‰¹é‡åˆ é™¤å¤±è´¥: ${err.message}`)
      return { success: false, error: err.message }
    }
  }, [conversations, currentConversation, messages])

  // å‘é€æ¶ˆæ¯
  const sendMessage = useCallback(async (message: string) => {
    if (!currentConversation) {
      setError('Please select or create a conversation first')
      return
    }

    setLoading(true)
    setError(null)
    
    console.log('ğŸš€ å¼€å§‹å‘é€æ¶ˆæ¯:', message)
    console.log('ğŸ“ å½“å‰å¯¹è¯:', currentConversation)
    
    // å»¶é•¿è¶…æ—¶æ—¶é—´åˆ°60ç§’
    const timeoutId = setTimeout(() => {
      console.warn('â° AIè¯·æ±‚è¶…æ—¶ï¼ˆ60ç§’ï¼‰ï¼Œè‡ªåŠ¨é‡ç½®loadingçŠ¶æ€')
      setLoading(false)
      setError('AI request timed out after 60 seconds. This might be due to OpenAI API issues. Please check your internet connection and try again.')
    }, 60000)
    
    try {
      // æ·»åŠ è¯·æ±‚å¼€å§‹æ—¶é—´è®°å½•
      const startTime = Date.now()
      console.log('â±ï¸ APIè¯·æ±‚å¼€å§‹æ—¶é—´:', new Date().toLocaleTimeString())
      
      const response = await aiConversationApi.sendMessage(
        currentConversation.id,
        message,
        {
          ...aiConfig,
          model: aiConfig.model || 'gpt-3.5-turbo' // ç¡®ä¿æœ‰é»˜è®¤æ¨¡å‹
        }
      )
      
      const duration = Date.now() - startTime
      console.log('â±ï¸ APIè¯·æ±‚å®Œæˆï¼Œè€—æ—¶:', duration + 'ms')
      console.log('ğŸ“¨ APIå“åº”:', response)
      
      if (response.error) {
        console.error('âŒ APIé”™è¯¯:', response.error)
        // æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹å®šçš„é”™è¯¯ç±»å‹
        if (response.error.includes('timeout') || response.error.includes('network')) {
          setError('Network connection issue. Please check your internet and try again.')
        } else if (response.error.includes('API key') || response.error.includes('authentication')) {
          setError('API authentication issue. Please check your OpenAI API key configuration.')
        } else if (response.error.includes('rate limit') || response.error.includes('quota')) {
          setError('OpenAI API rate limit exceeded. Please wait a moment and try again.')
        } else {
          setError(`AI Error: ${response.error}`)
        }
      } else {
        console.log('âœ… æ¶ˆæ¯å‘é€æˆåŠŸ:', response.data)
        const newMessage = response.data
        setMessages(prev => [...prev, newMessage])
        
        // æ›´æ–°å¯¹è¯åˆ—è¡¨ä¸­çš„æœ€åæ›´æ–°æ—¶é—´
        setConversations(prev => prev.map(conv => 
          conv.id === currentConversation.id 
            ? { ...conv, updated_at: newMessage.timestamp }
            : conv
        ))
      }
    } catch (err: any) {
      console.error('ğŸ’¥ å‘é€æ¶ˆæ¯å¼‚å¸¸:', err)
      
      // æ›´è¯¦ç»†çš„é”™è¯¯å¤„ç†
      if (err.name === 'TypeError' && err.message.includes('fetch')) {
        setError('Network error: Unable to connect to AI service. Please check your internet connection.')
      } else if (err.message.includes('timeout')) {
        setError('Request timeout: AI service took too long to respond. Please try again.')
      } else if (err.message.includes('CORS')) {
        setError('CORS error: Please check your API configuration.')
      } else {
        setError(`Unexpected error: ${err.message}`)
      }
    } finally {
      clearTimeout(timeoutId) // æ¸…é™¤è¶…æ—¶
      console.log('ğŸ æ¸…é™¤loadingçŠ¶æ€')
      setLoading(false)
    }
  }, [currentConversation, aiConfig])

  // ğŸš€ ä¼˜åŒ–ç‰ˆæœ¬ï¼šæ™®é€šå‘é€æ¶ˆæ¯ï¼ˆå®Œå…¨åˆ†ç¦»AIå’Œæ•°æ®åº“ï¼‰
  const sendMessageFast = useCallback(async (message: string, userMessage: AIMessage) => {
    if (!currentConversation) {
      setError('Please select or create a conversation first')
      return
    }

    setLoading(true)
    setError(null)
    
    console.log('ğŸš€ å¼€å§‹æ™®é€šAIè°ƒç”¨ï¼ˆå®Œå…¨åˆ†ç¦»ç‰ˆï¼‰:', message)
    
    // çŸ­è¶…æ—¶æ§åˆ¶ - ä»…é’ˆå¯¹AIè°ƒç”¨
    const timeoutId = setTimeout(() => {
      console.warn('â° AIè°ƒç”¨è¶…æ—¶ï¼ˆ20ç§’ï¼‰')
      setLoading(false)
      setError('AI response timeout. Please try again.')
    }, 20000) // å‡å°‘åˆ°20ç§’ï¼Œåªé’ˆå¯¹AIè°ƒç”¨
    
    try {
      const startTime = Date.now()

      // ğŸš€ æ ¸å¿ƒç­–ç•¥ï¼šåªç­‰å¾…AIè°ƒç”¨ï¼Œæ•°æ®åº“æ“ä½œå®Œå…¨åå°è¿›è¡Œ
      console.log('ğŸ¤– å¼€å§‹AIè°ƒç”¨ï¼ˆé™æ€å¯¼å…¥ï¼‰')
      
      const aiContent = await aiService.generateConversationResponse(
        currentConversation,
        message,
        {
          ...aiConfig,
          model: aiConfig.model || 'gpt-3.5-turbo'
        }
      )
      
      console.log('âœ… AIå“åº”å®Œæˆï¼Œè€—æ—¶:', Date.now() - startTime + 'ms')
      console.log('ğŸ¯ AIå›å¤å†…å®¹é•¿åº¦:', aiContent.length, 'å­—ç¬¦')

      // åˆ›å»ºAIæ¶ˆæ¯å¯¹è±¡
      const aiMessage: AIMessage = {
        id: `ai_${Date.now()}`,
        conversation_id: currentConversation.id,
        role: 'assistant',
        content: aiContent,
        timestamp: new Date().toISOString()
      }

      // ğŸš€ ç«‹å³æ·»åŠ åˆ°UI - æ— ç­‰å¾…
      setMessages(prev => [...prev, aiMessage])
      
      // æ›´æ–°å¯¹è¯åˆ—è¡¨ä¸­çš„æœ€åæ›´æ–°æ—¶é—´
      setConversations(prev => prev.map(conv => 
        conv.id === currentConversation.id 
          ? { ...conv, updated_at: aiMessage.timestamp }
          : conv
      ))
      
      console.log('âœ… AIæ¶ˆæ¯å·²æ·»åŠ åˆ°UIï¼Œæ€»è€—æ—¶:', Date.now() - startTime + 'ms')

      // ğŸ”¥ å®Œå…¨åå°çš„æ•°æ®åº“æ“ä½œ - ä¸é˜»å¡ä»»ä½•ç”¨æˆ·ä½“éªŒ
      Promise.resolve().then(async () => {
        try {
          console.log('ğŸ’¾ å¼€å§‹åå°æ•°æ®åº“æ“ä½œï¼ˆå®Œå…¨å¼‚æ­¥ï¼‰')
          
          // å¿«é€Ÿè®¤è¯æ£€æŸ¥
          const { data: { user }, error: authError } = await supabase.auth.getUser()
          if (authError || !user) {
            console.warn('âš ï¸ ç”¨æˆ·è®¤è¯å¤±è´¥ï¼Œè·³è¿‡æ•°æ®åº“æ“ä½œ')
            return
          }

          // å¹¶è¡Œä¿å­˜ç”¨æˆ·æ¶ˆæ¯å’ŒAIæ¶ˆæ¯
          const [userResult, aiResult] = await Promise.allSettled([
            // ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            supabase
              .from('ai_messages')
              .insert({
                conversation_id: currentConversation.id,
                role: 'user',
                content: message,
                timestamp: userMessage.timestamp
              }),
            
            // ä¿å­˜AIæ¶ˆæ¯
            supabase
              .from('ai_messages')
              .insert({
                conversation_id: currentConversation.id,
                role: 'assistant',
                content: aiContent,
                timestamp: aiMessage.timestamp
              })
          ])

          // å¤„ç†ç»“æœ
          if (userResult.status === 'fulfilled' && !userResult.value.error) {
            console.log('âœ… ç”¨æˆ·æ¶ˆæ¯å·²æŒä¹…åŒ–')
          } else {
            console.warn('âš ï¸ ç”¨æˆ·æ¶ˆæ¯æŒä¹…åŒ–å¤±è´¥:', userResult)
          }

          if (aiResult.status === 'fulfilled' && !aiResult.value.error) {
            console.log('âœ… AIæ¶ˆæ¯å·²æŒä¹…åŒ–')
          } else {
            console.warn('âš ï¸ AIæ¶ˆæ¯æŒä¹…åŒ–å¤±è´¥:', aiResult)
          }

          // æ›´æ–°å¯¹è¯æ—¶é—´æˆ³
          const conversationUpdate = await supabase
            .from('ai_conversations')
            .update({ updated_at: aiMessage.timestamp })
            .eq('id', currentConversation.id)

          if (!conversationUpdate.error) {
            console.log('âœ… å¯¹è¯æ—¶é—´æˆ³å·²æ›´æ–°')
          }

        } catch (dbErr) {
          console.warn('âš ï¸ åå°æ•°æ®åº“æ“ä½œå¤±è´¥ï¼Œä½†ä¸å½±å“ç”¨æˆ·ä½“éªŒ:', dbErr)
        }
      }).catch(err => {
        console.warn('âš ï¸ åå°ä»»åŠ¡å¯åŠ¨å¤±è´¥:', err)
      })

    } catch (err: any) {
      console.error('ğŸ’¥ AIè°ƒç”¨å¤±è´¥:', err)
      
      // ğŸš€ å¿«é€Ÿç”¨æˆ·å‹å¥½çš„é”™è¯¯å¤„ç†
      if (err.message.includes('timeout')) {
        setError('AIå“åº”è¶…æ—¶ï¼Œè¯·é‡è¯•')
      } else if (err.message.includes('API key')) {
        setError('APIé…ç½®é—®é¢˜ï¼Œè¯·æ£€æŸ¥è®¾ç½®')
      } else if (err.message.includes('rate limit')) {
        setError('è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åé‡è¯•')
      } else if (err.message.includes('network') || err.message.includes('fetch')) {
        setError('ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œè¯·é‡è¯•')
      } else {
        setError(`AIæœåŠ¡é”™è¯¯: ${err.message}`)
      }
    } finally {
      clearTimeout(timeoutId)
      setLoading(false)
      console.log('ğŸ AIè°ƒç”¨å®Œæˆ')
    }
  }, [currentConversation, aiConfig])

  // æ›´æ–° AI é…ç½®
  const updateAIConfig = useCallback((config: Partial<AIAssistantConfig>) => {
    const newConfig = { ...aiConfig, ...config }
    
    if (validateAIConfig(newConfig)) {
      setAIConfig(newConfig)
    } else {
      setError('Invalid AI configuration')
    }
  }, [aiConfig])

  // è·å– AI æ¨¡å¼é€‰é¡¹
  const getAIModeOptions = useCallback(() => {
    return Object.entries(AI_MODES).map(([key, value]) => ({
      value: key,
      label: value.name,
      description: value.description,
      icon: value.icon,
      color: value.color
    }))
  }, [])

  // è·å–å½“å‰ AI é…ç½®æè¿°
  const getCurrentConfigDescription = useCallback(() => {
    return getAIConfigDescription(aiConfig)
  }, [aiConfig])

  // æ¸…é™¤é”™è¯¯
  const clearError = useCallback(() => {
    setError(null)
  }, [])

  // å¼ºåˆ¶é‡ç½®loadingçŠ¶æ€
  const forceResetLoading = useCallback(() => {
    console.log('ğŸ”„ å¼ºåˆ¶é‡ç½®loadingçŠ¶æ€')
    setLoading(false)
    setError(null)
  }, [])

  // æ·»åŠ æ¶ˆæ¯åˆ°å½“å‰å¯¹è¯
  const addMessage = useCallback((message: AIMessage) => {
    console.log('â• æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯:', message)
    setMessages(prev => [...prev, message])
    
    // æ›´æ–°å¯¹è¯åˆ—è¡¨ä¸­çš„æœ€åæ›´æ–°æ—¶é—´
    if (currentConversation) {
      setConversations(prev => prev.map(conv => 
        conv.id === currentConversation.id 
          ? { ...conv, updated_at: message.timestamp }
          : conv
      ))
    }
  }, [currentConversation])

  // åˆå§‹åŒ–åŠ è½½
  useEffect(() => {
    fetchConversations()
  }, [fetchConversations])

  return {
    // çŠ¶æ€
    conversations,
    currentConversation,
    messages,
    loading,
    error,
    aiConfig,
    
    // æ–¹æ³•
    fetchConversations,
    createConversation,
    selectConversation,
    deleteConversation,
    deleteAllConversations,
    sendMessage,
    sendMessageFast,
    updateAIConfig,
    getAIModeOptions,
    getCurrentConfigDescription,
    clearError,
    forceResetLoading,
    addMessage
  }
}

// AI ç»Ÿè®¡ Hook
export const useAIStats = () => {
  const [stats, setStats] = useState({
    totalConversations: 0,
    totalMessages: 0,
    averageMessagesPerConversation: 0,
    mostUsedMode: 'bullet_tutor',
    mostUsedType: 'writing'
  })
  const [loading, setLoading] = useState(false)

  // è·å– AI ä½¿ç”¨ç»Ÿè®¡
  const fetchStats = useCallback(async () => {
    setLoading(true)
    try {
      // è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„ API
      // const response = await aiStatsApi.getUserStats()
      // setStats(response.data)
    } catch (error) {
      console.error('Failed to fetch AI stats:', error)
    } finally {
      setLoading(false)
    }
  }, [])

  useEffect(() => {
    fetchStats()
  }, [fetchStats])

  return {
    stats,
    loading,
    fetchStats
  }
} 