import { aiStreamService, StreamChunk, StreamOptions } from '@/api/ai-stream'
import { supabase } from '@/api/supabase'
import { AIAssistantConfig, AIConversation, AIMessage } from '@/types'
import { useCallback, useRef, useState } from 'react'

// æ‰©å±•æ¶ˆæ¯ç±»å‹ä»¥æ”¯æŒæµå¼å“åº”éœ€è¦çš„å­—æ®µ
interface StreamMessage extends Omit<AIMessage, 'id' | 'timestamp'> {
  assistant_type?: string
  mode?: string
}

export interface UseAIStreamReturn {
  isStreaming: boolean
  streamingMessage: string
  sendStreamMessage: (message: string, conversation: AIConversation, config?: AIAssistantConfig) => Promise<void>
  stopStreaming: () => void
  error: string | null
  clearError: () => void
}

export function useAIStream(): UseAIStreamReturn {
  const [isStreaming, setIsStreaming] = useState(false)
  const [streamingMessage, setStreamingMessage] = useState('')
  const [error, setError] = useState<string | null>(null)
  const streamingRef = useRef<boolean>(false)
  const abortControllerRef = useRef<AbortController | null>(null)

  // æ¸…é™¤é”™è¯¯
  const clearError = useCallback(() => {
    setError(null)
  }, [])

  // åœæ­¢æµå¼å“åº”
  const stopStreaming = useCallback(() => {
    streamingRef.current = false
    abortControllerRef.current?.abort()
    setIsStreaming(false)
    setStreamingMessage('')
  }, [])

  // å‘é€æµå¼æ¶ˆæ¯
  const sendStreamMessage = useCallback(async (
    message: string,
    conversation: AIConversation,
    config?: AIAssistantConfig
  ) => {
    if (isStreaming || !message.trim()) {
      return
    }

    console.log('ğŸš€ å¼€å§‹æµå¼æ¶ˆæ¯å‘é€:', message)
    setError(null)
    setIsStreaming(true)
    setStreamingMessage('')
    streamingRef.current = true

    // åˆ›å»ºæ–°çš„AbortController
    abortControllerRef.current = new AbortController()

    try {
      // 1. ç«‹å³ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“
      const userMessageData: StreamMessage = {
        conversation_id: conversation.id,
        role: 'user',
        content: message,
        assistant_type: conversation.assistant_type,
        mode: config?.mode || 'bullet_tutor'
      }

      const { data: savedUserMessage, error: userMessageError } = await supabase
        .from('ai_messages')
        .insert(userMessageData)
        .select()
        .single()

      if (userMessageError) {
        console.error('âŒ ä¿å­˜ç”¨æˆ·æ¶ˆæ¯å¤±è´¥:', userMessageError)
        throw new Error('ä¿å­˜æ¶ˆæ¯å¤±è´¥')
      }

      console.log('âœ… ç”¨æˆ·æ¶ˆæ¯å·²ä¿å­˜:', savedUserMessage)

      // 2. åˆ›å»ºAIæ¶ˆæ¯è®°å½•ï¼ˆåˆå§‹ä¸ºç©ºï¼‰
      const aiMessageData: StreamMessage = {
        conversation_id: conversation.id,
        role: 'assistant',
        content: '', // åˆå§‹ä¸ºç©ºï¼Œæµå¼æ›´æ–°
        assistant_type: conversation.assistant_type,
        mode: config?.mode || 'bullet_tutor'
      }

      const { data: aiMessage, error: aiMessageError } = await supabase
        .from('ai_messages')
        .insert(aiMessageData)
        .select()
        .single()

      if (aiMessageError) {
        console.error('âŒ åˆ›å»ºAIæ¶ˆæ¯å¤±è´¥:', aiMessageError)
        throw new Error('åˆ›å»ºAIæ¶ˆæ¯å¤±è´¥')
      }

      console.log('âœ… AIæ¶ˆæ¯è®°å½•å·²åˆ›å»º:', aiMessage)

      // 3. å¼€å§‹æµå¼AIè°ƒç”¨
      let fullAIContent = ''

      const streamOptions: StreamOptions = {
        onChunk: (chunk: StreamChunk) => {
          if (!streamingRef.current) return

          // æ›´æ–°æµå¼æ¶ˆæ¯æ˜¾ç¤º
          fullAIContent += chunk.content
          setStreamingMessage(fullAIContent)
          
          console.log('ğŸ“ æ”¶åˆ°æµå¼å—:', chunk.content)
        },

        onComplete: async (fullContent: string) => {
          if (!streamingRef.current) return

          console.log('âœ… æµå¼å“åº”å®Œæˆï¼Œæ€»é•¿åº¦:', fullContent.length)

          try {
            // æ›´æ–°æ•°æ®åº“ä¸­çš„AIæ¶ˆæ¯å†…å®¹
            const { error: updateError } = await supabase
              .from('ai_messages')
              .update({ content: fullContent })
              .eq('id', aiMessage.id)

            if (updateError) {
              console.error('âŒ æ›´æ–°AIæ¶ˆæ¯å¤±è´¥:', updateError)
            } else {
              console.log('âœ… AIæ¶ˆæ¯å†…å®¹å·²æ›´æ–°åˆ°æ•°æ®åº“')
            }
          } catch (updateErr) {
            console.error('ğŸ’¥ æ›´æ–°æ¶ˆæ¯æ—¶å‡ºé”™:', updateErr)
          }

          // æ¸…ç†çŠ¶æ€
          setIsStreaming(false)
          setStreamingMessage('')
          streamingRef.current = false
        },

        onError: (errorMessage: string) => {
          console.error('ğŸ’¥ æµå¼å“åº”é”™è¯¯:', errorMessage)
          setError(errorMessage)
          setIsStreaming(false)
          setStreamingMessage('')
          streamingRef.current = false

          // åˆ é™¤æœªå®Œæˆçš„AIæ¶ˆæ¯è®°å½•
          supabase
            .from('ai_messages')
            .delete()
            .eq('id', aiMessage.id)
            .then(() => console.log('ğŸ—‘ï¸ å·²åˆ é™¤æœªå®Œæˆçš„AIæ¶ˆæ¯'))
        }
      }

      // å¯åŠ¨æµå¼è°ƒç”¨
      await aiStreamService.streamCompletion(
        conversation,
        message,
        config || { mode: 'bullet_tutor' },
        streamOptions
      )

    } catch (err: any) {
      console.error('ğŸ’¥ æµå¼æ¶ˆæ¯å‘é€å¤±è´¥:', err)
      setError(err.message || 'å‘é€æ¶ˆæ¯å¤±è´¥ï¼Œè¯·é‡è¯•')
      setIsStreaming(false)
      setStreamingMessage('')
      streamingRef.current = false
    }
  }, [isStreaming])

  return {
    isStreaming,
    streamingMessage,
    sendStreamMessage,
    stopStreaming,
    error,
    clearError
  }
} 