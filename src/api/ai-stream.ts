import { AIAssistantConfig, AIConversation } from '@/types'

// æµå¼å“åº”ç±»å‹å®šä¹‰
export interface StreamChunk {
  content: string
  isComplete: boolean
  error?: string
}

export interface StreamOptions {
  onChunk: (chunk: StreamChunk) => void
  onComplete: (fullContent: string) => void
  onError: (error: string) => void
}

// AI æç¤ºè¯æ¨¡æ¿ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
const AI_PROMPTS = {
  writing: {
    bullet_tutor: `ä½ æ˜¯å­¦æœ¯å†™ä½œå¯¼å¸ˆã€‚ç®€æ´å›ç­”ï¼Œæ§åˆ¶åœ¨150å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`,
    socratic_bot: `ä½ æ˜¯è‹æ ¼æ‹‰åº•å¼å¯¼å¸ˆã€‚ç”¨é—®é¢˜å¼•å¯¼æ€è€ƒï¼Œ100å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`,
    quick_fix: `ç›´æ¥æä¾›å†™ä½œå»ºè®®ï¼Œ80å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`,
    diagram_ai: `ç”¨ç®€å•å›¾è¡¨è¯´æ˜ï¼Œ100å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`
  },
  stem: {
    bullet_tutor: `ä½ æ˜¯STEMå¯¼å¸ˆã€‚å¼•å¯¼å¼æ•™å­¦ï¼Œ150å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`,
    socratic_bot: `ç”¨é—®é¢˜å¼•å¯¼STEMæ€ç»´ï¼Œ100å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`,
    quick_fix: `ç›´æ¥æä¾›è§£é¢˜æ­¥éª¤ï¼Œ80å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`,
    diagram_ai: `ç”¨å›¾è¡¨è§£é‡Šæ¦‚å¿µï¼Œ100å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`
  },
  reading: {
    bullet_tutor: `ä½ æ˜¯é˜…è¯»å¯¼å¸ˆã€‚å¼•å¯¼ç†è§£ï¼Œ150å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`,
    socratic_bot: `ç”¨é—®é¢˜æ·±åŒ–ç†è§£ï¼Œ100å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`,
    quick_fix: `ç›´æ¥è§£é‡Šè¦ç‚¹ï¼Œ80å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`,
    diagram_ai: `ç”¨å›¾è¡¨åˆ†ææ–‡æœ¬ï¼Œ100å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`
  },
  programming: {
    bullet_tutor: `ä½ æ˜¯ç¼–ç¨‹å¯¼å¸ˆã€‚å¼•å¯¼æ€ç»´ï¼Œ150å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`,
    socratic_bot: `ç”¨é—®é¢˜å¼•å¯¼ç¼–ç¨‹é€»è¾‘ï¼Œ100å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`,
    quick_fix: `ç›´æ¥æä¾›ä»£ç æ–¹æ¡ˆï¼Œ80å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`,
    diagram_ai: `ç”¨æµç¨‹å›¾è§£é‡Šï¼Œ100å­—å†…ã€‚\n\né—®é¢˜ï¼š{user_message}`
  }
}

export class AIStreamService {
  private apiKey: string
  private baseUrl: string

  constructor() {
    this.apiKey = import.meta.env.VITE_OPENAI_API_KEY
    this.baseUrl = 'https://api.openai.com/v1'
  }

  /**
   * æµå¼è°ƒç”¨OpenAI API
   */
  async streamCompletion(
    conversation: AIConversation,
    userMessage: string,
    config: AIAssistantConfig,
    options: StreamOptions
  ): Promise<void> {
    try {
      if (!this.apiKey) {
        throw new Error('OpenAI API key not configured')
      }

      console.log('ğŸš€ å¼€å§‹æµå¼AIè°ƒç”¨:', userMessage)
      const startTime = Date.now()

      // æ„å»ºä¼˜åŒ–çš„æç¤ºè¯
      const assistantType = conversation.assistant_type
      const mode = config?.mode || 'bullet_tutor'
      const promptTemplate = AI_PROMPTS[assistantType]?.[mode] || AI_PROMPTS[assistantType]?.bullet_tutor
      
      const systemPrompt = promptTemplate.replace('{user_message}', userMessage)

      const messages = [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userMessage }
      ]

      // åˆ›å»ºAbortControllerç”¨äºè¶…æ—¶æ§åˆ¶
      const controller = new AbortController()
      const timeoutId = setTimeout(() => {
        console.warn('â° æµå¼è¯·æ±‚è¶…æ—¶ï¼Œå–æ¶ˆè¯·æ±‚')
        controller.abort()
        options.onError('è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•')
      }, 15000) // 15ç§’è¶…æ—¶

      const response = await fetch(`${this.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: config?.model || 'gpt-3.5-turbo',
          messages,
          max_tokens: 400, // è¿›ä¸€æ­¥å‡å°‘token
          temperature: 0.7,
          top_p: 0.9,
          stream: true, // å¯ç”¨æµå¼å“åº”
          frequency_penalty: 0,
          presence_penalty: 0
        }),
        signal: controller.signal
      })

      clearTimeout(timeoutId)

      if (!response.ok) {
        const errorText = await response.text()
        console.error('âŒ æµå¼APIé”™è¯¯:', errorText)
        options.onError(`APIé”™è¯¯: ${response.statusText}`)
        return
      }

      console.log(`ğŸ“¡ æµå¼å“åº”å¼€å§‹ (${Date.now() - startTime}ms)`)

      // å¤„ç†æµå¼å“åº”
      const reader = response.body?.getReader()
      if (!reader) {
        options.onError('æ— æ³•è¯»å–å“åº”æµ')
        return
      }

      const decoder = new TextDecoder()
      let buffer = ''
      let fullContent = ''

      try {
        while (true) {
          const { done, value } = await reader.read()
          
          if (done) {
            console.log(`âœ… æµå¼å“åº”å®Œæˆ (æ€»è€—æ—¶: ${Date.now() - startTime}ms)`)
            options.onComplete(fullContent)
            break
          }

          // è§£ç æ•°æ®
          buffer += decoder.decode(value, { stream: true })
          
          // å¤„ç†SSEæ ¼å¼çš„æ•°æ®
          const lines = buffer.split('\n')
          buffer = lines.pop() || '' // ä¿ç•™æœªå®Œæˆçš„è¡Œ

          for (const line of lines) {
            if (line.startsWith('data: ')) {
              const data = line.slice(6).trim()
              
              if (data === '[DONE]') {
                options.onComplete(fullContent)
                return
              }

              try {
                const parsed = JSON.parse(data)
                const content = parsed.choices?.[0]?.delta?.content || ''
                
                if (content) {
                  fullContent += content
                  
                  // å‘é€æµå¼æ•°æ®å—
                  options.onChunk({
                    content: content,
                    isComplete: false
                  })
                }
              } catch (parseError) {
                console.warn('è§£ææµå¼æ•°æ®å¤±è´¥:', parseError)
              }
            }
          }
        }
      } catch (streamError) {
        console.error('ğŸ’¥ æµå¼å¤„ç†é”™è¯¯:', streamError)
        options.onError('æµå¼å¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•')
      } finally {
        reader.releaseLock()
      }

    } catch (error: any) {
      console.error('ğŸ’¥ æµå¼APIè°ƒç”¨å¤±è´¥:', error)
      
      if (error.name === 'AbortError') {
        options.onError('è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•')
      } else if (error.message.includes('fetch')) {
        options.onError('ç½‘ç»œè¿æ¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œ')
      } else {
        options.onError(`AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨: ${error.message}`)
      }
    }
  }
}

// åˆ›å»ºå…¨å±€å®ä¾‹
export const aiStreamService = new AIStreamService() 