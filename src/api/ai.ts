import { getModeConfig } from '@/config/aiModeConfigs';
import { AIAssistantConfig, AIConversation, AIMessage, AIModeId, ApiResponse, ReviewCard, WeeklyReport } from '@/types';
import { checkFileSizeLimit } from '@/utils';
import { getAIModel } from '../config/aiModel';
import { supabase } from './supabase';


// Legacy AI prompts mapping (for backward compatibility)
const LEGACY_AI_PROMPTS = {
  writing: {
    bullet_tutor: 'study_buddy',
    socratic_bot: 'academic_coach', 
    quick_fix: 'quick_clarifier',
    diagram_ai: 'writing_mentor'
  },
  stem: {
    bullet_tutor: 'study_buddy',
    socratic_bot: 'academic_coach',
    quick_fix: 'quick_clarifier', 
    diagram_ai: 'stem_specialist'
  },
  reading: {
    bullet_tutor: 'study_buddy',
    socratic_bot: 'academic_coach',
    quick_fix: 'quick_clarifier',
    diagram_ai: 'humanities_scholar'
  },
  programming: {
    bullet_tutor: 'study_buddy', 
    socratic_bot: 'academic_coach',
    quick_fix: 'quick_clarifier',
    diagram_ai: 'stem_specialist'
  }
}

// OpenAI API é…ç½®
const OPENAI_API_KEY = import.meta.env.VITE_OPENAI_API_KEY;
const OPENAI_API_URL = 'https://api.openai.com/v1/chat/completions';
const OPENAI_MODEL = getAIModel();

// AI æœåŠ¡ç±»
class AIService {
  private apiKey: string
  private baseUrl: string

  constructor() {
    this.apiKey = import.meta.env.VITE_OPENAI_API_KEY
    this.baseUrl = 'https://api.openai.com/v1'
  }

  // è°ƒç”¨ OpenAI API
  async callOpenAI(messages: any[], config?: Partial<any>): Promise<string> {
    try {
      if (!this.apiKey) {
        throw new Error('OpenAI API key not configured')
      }

      // ç¡®å®šä½¿ç”¨çš„æ¨¡å‹
      const model = config?.model || getAIModel()
      
      // ğŸš€ æ¿€è¿›æ€§èƒ½ä¼˜åŒ– - å¤§å¹…å‡å°‘Tokenå’Œæ—¶é—´
      const maxTokens = model === 'gpt-4o' ? 500 : 400  // è¿›ä¸€æ­¥å‡å°‘Tokenæ•°é‡ï¼Œæå‡é€Ÿåº¦
      const temperature = model === 'gpt-4o' ? 0.5 : 0.6  // æé«˜æ¸©åº¦ï¼Œå‡å°‘æ¨ç†æ—¶é—´

      console.log('ğŸ”¥ å¼€å§‹è°ƒç”¨OpenAI API:', model, `(max_tokens: ${maxTokens})`)
      console.log('ğŸ“ å‘é€æ¶ˆæ¯é•¿åº¦:', JSON.stringify(messages).length, 'å­—ç¬¦')

      // åˆ›å»ºAbortControllerç”¨äºè¶…æ—¶æ§åˆ¶
      const controller = new AbortController()
      const timeoutId = setTimeout(() => {
        console.warn('â° OpenAI APIè¯·æ±‚è¶…æ—¶ï¼Œå–æ¶ˆè¯·æ±‚')
        controller.abort()
      }, 15000) // ğŸš€ å‡å°‘åˆ°15ç§’è¶…æ—¶ï¼Œæ¿€è¿›ä¼˜åŒ–

      const startTime = Date.now()

      const response = await fetch(`${this.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: model,
          messages,
          max_tokens: config?.max_tokens || maxTokens,
          temperature: config?.temperature || temperature,
          top_p: config?.top_p || 0.8,  // è¿›ä¸€æ­¥é™ä½ï¼Œæå‡ç”Ÿæˆé€Ÿåº¦
          frequency_penalty: config?.frequency_penalty || 0.1,  // è½»å¾®æƒ©ç½šï¼Œæå‡é€Ÿåº¦
          presence_penalty: config?.presence_penalty || 0.1,    // è½»å¾®æƒ©ç½šï¼Œæå‡é€Ÿåº¦
          stream: false  // ç¡®ä¿ä¸ä½¿ç”¨æµå¼å“åº”
        }),
        signal: controller.signal // æ·»åŠ ä¿¡å·ç”¨äºå–æ¶ˆè¯·æ±‚
      })

      const duration = Date.now() - startTime
      clearTimeout(timeoutId) // æ¸…é™¤è¶…æ—¶è®¡æ—¶å™¨
      console.log(`ğŸ“¡ OpenAI APIå“åº” (${duration}ms):`, response.status)

      if (!response.ok) {
        const errorText = await response.text()
        console.error('âŒ OpenAI APIå“åº”é”™è¯¯:', errorText)
        
        let error
        try {
          error = JSON.parse(errorText)
        } catch {
          error = { error: { message: errorText } }
        }
        
        throw new Error(`OpenAI API error: ${error.error?.message || response.statusText}`)
      }

      const data = await response.json()
      console.log(`âœ… OpenAI APIè°ƒç”¨æˆåŠŸ (æ€»è€—æ—¶: ${Date.now() - startTime}ms)`)
      console.log('ğŸ”¢ Tokenä½¿ç”¨æƒ…å†µ:', data.usage)
      
      const content = data.choices[0]?.message?.content || 'æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›å¤ã€‚'
      return content
    } catch (error: any) {
      console.error('ğŸ’¥ OpenAI APIè°ƒç”¨å¤±è´¥:', error)
      
      if (error.name === 'AbortError') {
        throw new Error('è¯·æ±‚è¶…æ—¶ï¼šAIæœåŠ¡å“åº”æ—¶é—´è¿‡é•¿ï¼Œè¯·ç¨åé‡è¯•')
      } else if (error.message.includes('fetch')) {
        throw new Error('ç½‘ç»œè¿æ¥é”™è¯¯ï¼šæ— æ³•è¿æ¥åˆ°AIæœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥')
      } else {
        throw new Error(`AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨: ${error.message}`)
      }
    }
  }

  // ç”Ÿæˆå¯¹è¯å›å¤ - Updated for new English prompt system
  async generateConversationResponse(
    conversation: AIConversation,
    userMessage: string,
    config?: AIAssistantConfig
  ): Promise<string> {
    const modeId = config?.mode || 'study_buddy' as AIModeId
    
    // Get the AI mode configuration
    const modeConfig = getModeConfig(modeId)
    
    if (!modeConfig) {
      // Fallback to legacy mapping for backward compatibility
      const assistantType = conversation.assistant_type
      const legacyMode = config?.mode
      
      // Only use legacy mapping for old mode types
      const legacyModeMapping = {
        'bullet_tutor': 'bullet_tutor',
        'socratic_bot': 'socratic_bot', 
        'quick_fix': 'quick_fix',
        'diagram_ai': 'diagram_ai'
      } as const
      
      const mappedLegacyMode = legacyMode && legacyMode in legacyModeMapping 
        ? legacyModeMapping[legacyMode as keyof typeof legacyModeMapping]
        : 'bullet_tutor'
      
      const fallbackModeId = LEGACY_AI_PROMPTS[assistantType]?.[mappedLegacyMode] || 'study_buddy'
      const fallbackConfig = getModeConfig(fallbackModeId)
      
      if (!fallbackConfig) {
        throw new Error(`Unsupported AI mode: ${modeId}`)
      }
      
      console.log(`ğŸ”„ Using fallback mode: ${fallbackModeId} for legacy mode: ${mappedLegacyMode}`)
      return this.generateResponseWithConfig(fallbackConfig, conversation, userMessage, config)
    }

    return this.generateResponseWithConfig(modeConfig, conversation, userMessage, config)
  }

  // Helper method to generate response with mode configuration
  private async generateResponseWithConfig(
    modeConfig: any,
    conversation: AIConversation,
    userMessage: string,
    config?: AIAssistantConfig
  ): Promise<string> {
    // Build the system prompt using the English template
    const taskTitle = conversation.task_id ? 'Related Assignment' : 'Learning Support'
    const systemPrompt = modeConfig.promptTemplate
      .replace('{task_title}', taskTitle)
      .replace('{user_message}', userMessage)

    // Add academic version context
    const academicContext = config?.academicVersion === 'high_school' 
      ? '\n\nNote: This is for a high school student. Keep explanations age-appropriate and supportive.'
      : '\n\nNote: This is for a college student. Encourage critical thinking and independent analysis.'

    const finalSystemPrompt = systemPrompt + academicContext

    // Build message history
    const messages = [
      { role: 'system', content: finalSystemPrompt },
      { role: 'user', content: userMessage }
    ]

    // Use the mode's specific token limit
    const modelConfig = {
      ...config,
      max_tokens: modeConfig.maxTokens || 400,
      model: config?.model || getAIModel()
    }

    return await this.callOpenAI(messages, modelConfig)
  }

  // ç”Ÿæˆå¤ä¹ å¡ç‰‡
  async generateReviewCards(courseContent: any): Promise<Omit<ReviewCard, 'id' | 'course_id' | 'created_at'>[]> {
    const systemPrompt = `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¯¾ç¨‹å¤ä¹ å¡ç‰‡ç”Ÿæˆä¸“å®¶ã€‚è¯·æ ¹æ®æä¾›çš„è¯¾ç¨‹å†…å®¹ç”Ÿæˆé«˜è´¨é‡çš„å¤ä¹ å¡ç‰‡ã€‚

è¦æ±‚ï¼š
1. ç”Ÿæˆ 5-8 å¼ å¤ä¹ å¡ç‰‡
2. æ¯å¼ å¡ç‰‡åŒ…å«é—®é¢˜å’Œç­”æ¡ˆ
3. æ¶µç›–åŸºç¡€æ¦‚å¿µã€åº”ç”¨ç†è®ºå’Œé‡ç‚¹å…¬å¼
4. éš¾åº¦åˆ†å¸ƒï¼šç®€å• 30%ï¼Œä¸­ç­‰ 50%ï¼Œå›°éš¾ 20%
5. é—®é¢˜è¦å…·ä½“ä¸”æœ‰å¯å‘æ€§
6. ç­”æ¡ˆè¦å‡†ç¡®ä¸”æ˜“äºç†è§£

è¯¾ç¨‹å†…å®¹ï¼š${JSON.stringify(courseContent, null, 2)}

è¯·ä»¥ JSON æ ¼å¼è¿”å›å¤ä¹ å¡ç‰‡æ•°ç»„ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  {
    "question": "é—®é¢˜å†…å®¹",
    "answer": "ç­”æ¡ˆå†…å®¹", 
    "category": "åˆ†ç±»",
    "difficulty": "easy|medium|hard"
  }
]`

    try {
      const response = await this.callOpenAI([
        { role: 'system', content: systemPrompt }
      ])

      // å°è¯•è§£æ JSON å“åº”
      const jsonMatch = response.match(/\[[\s\S]*\]/)
      if (jsonMatch) {
        const cards = JSON.parse(jsonMatch[0])
        return cards.map((card: any) => ({
          ...card,
          mastery_level: 0
        }))
      }

      // å¦‚æœæ— æ³•è§£æ JSONï¼Œè¿”å›é»˜è®¤å¡ç‰‡
      return this.getDefaultReviewCards()
    } catch (error) {
      console.error('Failed to generate review cards:', error)
      return this.getDefaultReviewCards()
    }
  }

  // ç”Ÿæˆå‘¨æŠ¥å‘Šå»ºè®®
  async generateWeeklyRecommendations(stats: any, tasks: any[]): Promise<string[]> {
    const systemPrompt = `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦ä¹ æ•™ç»ƒã€‚è¯·æ ¹æ®å­¦ç”Ÿçš„å­¦ä¹ æ•°æ®ç”Ÿæˆä¸ªæ€§åŒ–çš„å»ºè®®ã€‚

å­¦ä¹ ç»Ÿè®¡ï¼š
- ä»»åŠ¡å®Œæˆç‡: ${stats.completion_rate}%
- å­¦ä¹ æ—¶é—´: ${stats.study_hours} å°æ—¶
- æ‹–å»¶æŒ‡æ•°: ${stats.procrastination_index}/10
- ä¸“æ³¨åº¦è¯„åˆ†: ${stats.focus_score}/100

ä»»åŠ¡æƒ…å†µï¼š
${tasks.map(task => `- ${task.title}: ${task.status}`).join('\n')}

è¯·ç”Ÿæˆ 3-5 æ¡å…·ä½“ã€å¯æ“ä½œçš„å»ºè®®ï¼Œå¸®åŠ©å­¦ç”Ÿåœ¨ä¸‹å‘¨æé«˜å­¦ä¹ æ•ˆç‡ã€‚å»ºè®®è¦ï¼š
1. é’ˆå¯¹æ€§å¼ºï¼ŒåŸºäºå…·ä½“æ•°æ®
2. å¯æ“ä½œï¼Œæœ‰æ˜ç¡®çš„è¡ŒåŠ¨æ­¥éª¤
3. ç§¯ææ­£é¢ï¼Œé¼“åŠ±å­¦ç”Ÿ
4. ä¸è¶…è¿‡ 50 å­—

è¯·ç›´æ¥è¿”å›å»ºè®®åˆ—è¡¨ï¼Œæ¯æ¡å»ºè®®ä¸€è¡Œã€‚`

    try {
      const response = await this.callOpenAI([
        { role: 'system', content: systemPrompt }
      ])

      return response.split('\n').filter(line => line.trim().length > 0)
    } catch (error) {
      console.error('Failed to generate recommendations:', error)
      return ['æœ¬å‘¨è¡¨ç°è‰¯å¥½ï¼Œç»§ç»­ä¿æŒï¼']
    }
  }

  // è§£æè¯¾ç¨‹ææ–™
  async parseCourseMaterials(materials: any[]): Promise<any> {
    // æ‹¼æ¥æ‰€æœ‰ææ–™æ–‡æœ¬
    const materialsText = materials.map(m => `${m.name}:\n${m.extracted_text || 'æ— æ–‡æœ¬å†…å®¹'}`).join('\n\n');
    
    // æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦è¶…è¿‡GPT-4oçš„tokené™åˆ¶
    const sizeCheck = checkFileSizeLimit(materialsText)
    if (sizeCheck.isOverLimit) {
      throw new Error(`æ–‡ä»¶å†…å®¹è¿‡å¤§ï¼å½“å‰å­—ç¬¦æ•°ï¼š${sizeCheck.characterCount.toLocaleString()}ï¼Œè¶…è¿‡GPT-4oé™åˆ¶ï¼š${sizeCheck.limit.toLocaleString()}ã€‚è¯·ä¸Šä¼ è¾ƒå°çš„æ–‡ä»¶æˆ–åˆ†å‰²æ–‡ä»¶å†…å®¹ã€‚`)
    }
    
    const systemPrompt = `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¯¾ç¨‹ææ–™è§£æä¸“å®¶ã€‚è¯·åˆ†ææä¾›çš„è¯¾ç¨‹ææ–™ï¼Œæå–å…³é”®ä¿¡æ¯å¹¶ç”Ÿæˆç»“æ„åŒ–æ•°æ®ã€‚\n\nè¦æ±‚ï¼š\n1. è¯†åˆ«è¯¾ç¨‹åç§°ã€å­¦æœŸã€å¹´ä»½\n2. æå–æ‰€æœ‰ä»»åŠ¡ã€ä½œä¸šã€è€ƒè¯•ä¿¡æ¯\n3. è¯†åˆ«è¯„åˆ†æ”¿ç­–å’Œè¯¾ç¨‹é‡ç‚¹\n4. ç”Ÿæˆä»»åŠ¡æ—¶é—´çº¿\n5. æä¾›è¯¾ç¨‹æè¿°\n\nè¯·ä»¥ JSON æ ¼å¼è¿”å›è§£æç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n{\n  "course_name": "è¯¾ç¨‹åç§°",\n  "semester": "å­¦æœŸ",\n  "year": å¹´ä»½,\n  "course_description": "è¯¾ç¨‹æè¿°",\n  "grading_policy": "è¯„åˆ†æ”¿ç­–",\n  "tasks": [\n    {\n      "title": "ä»»åŠ¡æ ‡é¢˜",\n      "type": "reading|writing|assignment|exam|quiz|project|presentation",\n      "due_date": "YYYY-MM-DD",\n      "priority": "low|medium|high",\n      "estimated_hours": æ•°å­—,\n      "description": "ä»»åŠ¡æè¿°"\n    }\n  ]\n}`;
    try {
      const headers = {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${OPENAI_API_KEY}`,
      };
      const response = await fetch(OPENAI_API_URL, {
        method: 'POST',
        headers,
        body: JSON.stringify({
          model: OPENAI_MODEL,
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: `è¯·è§£æä»¥ä¸‹è¯¾ç¨‹ææ–™ï¼š\n\n${materialsText}` }
          ],
          temperature: 0.2,
          max_tokens: 1500,
        }),
      });
      const result = await response.json();
      const content = result.choices?.[0]?.message?.content || '';
      // å°è¯•æå–JSON
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const parsedData = JSON.parse(jsonMatch[0]);
        // gradingæç¤º
        const gradingNotice = 'åªè‡ªåŠ¨ç”Ÿæˆäº†ä¸è¯„åˆ†æƒé‡æœ‰å…³çš„ä»»åŠ¡ï¼Œå…¶ä»–ä»»åŠ¡è¯·åœ¨ä¸‹æ–¹æ‰‹åŠ¨è¡¥å……ã€‚';
        // è¡¥å…¨æ‰€æœ‰ä»»åŠ¡çš„estimated_hourså­—æ®µï¼Œé»˜è®¤2å°æ—¶
        parsedData.tasks = parsedData.tasks.map((t: any) => ({
          ...t,
          estimated_hours: t.estimated_hours == null ? 2 : t.estimated_hours
        }));
        return { ...parsedData, gradingNotice };
      }
      // å¦‚æœAIè§£æå¤±è´¥ï¼ŒæŠ›å‡ºé”™è¯¯è€Œä¸æ˜¯è¿”å›é»˜è®¤æ¨¡æ¿
      throw new Error('AIè§£æå¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆè¯¾ç¨‹ç»“æ„ã€‚è¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹æˆ–ç¨åé‡è¯•ã€‚');
    } catch (error) {
      console.error('AIè§£æå¤±è´¥:', error);
      // å¦‚æœæ˜¯æ–‡ä»¶å¤§å°é™åˆ¶é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
      if (error instanceof Error && error.message.includes('æ–‡ä»¶å†…å®¹è¿‡å¤§')) {
        throw error;
      }
      // å…¶ä»–é”™è¯¯ä¹ŸæŠ›å‡ºï¼Œä¸å†è¿”å›é»˜è®¤æ¨¡æ¿
      throw new Error('AIè§£æå¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆè¯¾ç¨‹ç»“æ„ã€‚è¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹æˆ–ç¨åé‡è¯•ã€‚');
    }
  }

  // é»˜è®¤å¤ä¹ å¡ç‰‡
  private getDefaultReviewCards(): Omit<ReviewCard, 'id' | 'course_id' | 'created_at'>[] {
    return [
      {
        question: 'ä»€ä¹ˆæ˜¯è¯¾ç¨‹çš„æ ¸å¿ƒæ¦‚å¿µï¼Ÿ',
        answer: 'æ ¹æ®è¯¾ç¨‹ææ–™ï¼Œæ ¸å¿ƒæ¦‚å¿µåŒ…æ‹¬åŸºç¡€ç†è®ºã€é‡è¦æ–¹æ³•å’Œå…³é”®åº”ç”¨ã€‚',
        category: 'åŸºç¡€æ¦‚å¿µ',
        difficulty: 'easy',
        mastery_level: 0
      },
      {
        question: 'å¦‚ä½•åº”ç”¨è¯¾ç¨‹ä¸­çš„ä¸»è¦ç†è®ºï¼Ÿ',
        answer: 'ä¸»è¦ç†è®ºçš„åº”ç”¨éœ€è¦ç†è§£å…¶åŸºæœ¬åŸç†ï¼Œç»“åˆå®é™…æ¡ˆä¾‹è¿›è¡Œåˆ†æå’ŒéªŒè¯ã€‚',
        category: 'åº”ç”¨ç†è®º',
        difficulty: 'medium',
        mastery_level: 0
      },
      {
        question: 'è¯¾ç¨‹ä¸­æœ€é‡è¦çš„å…¬å¼æˆ–æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ',
        answer: 'æœ€é‡è¦çš„å…¬å¼å’Œæ–¹æ³•æ˜¯è¯¾ç¨‹çš„æ ¸å¿ƒå·¥å…·ï¼Œéœ€è¦ç†Ÿç»ƒæŒæ¡å…¶æ¨å¯¼å’Œåº”ç”¨ã€‚',
        category: 'å…¬å¼è®°å¿†',
        difficulty: 'hard',
        mastery_level: 0
      }
    ]
  }

  // é»˜è®¤è¯¾ç¨‹è§£æ
  private getDefaultCourseParse() {
    return {
      course_name: 'ç¤ºä¾‹è¯¾ç¨‹',
      semester: 'Fall',
      year: 2024,
      course_description: 'è¯¾ç¨‹æè¿°',
      grading_policy: 'åŸºäºä½œä¸šå’Œè€ƒè¯•',
      tasks: []
    }
  }
}

// åˆ›å»º AI æœåŠ¡å®ä¾‹
const aiService = new AIService()

// å¯¼å‡º AI æœåŠ¡å®ä¾‹
export { aiService };

// AI å¯¹è¯ API
export const aiConversationApi = {
  // åˆ›å»ºæ–°çš„ AI å¯¹è¯
  async createConversation(
    assistantType: AIConversation['assistant_type'],
    taskId?: string
  ): Promise<ApiResponse<AIConversation>> {
    try {
      const { data: { user } } = await supabase.auth.getUser()
      if (!user) throw new Error('ç”¨æˆ·æœªç™»å½•')

      const { data, error } = await supabase
        .from('ai_conversations')
        .insert([{
          user_id: user.id,
          task_id: taskId,
          assistant_type: assistantType
        }])
        .select()
        .single()

      if (error) throw error
      return { data }
    } catch (error: any) {
      return { data: {} as AIConversation, error: error.message }
    }
  },

  // è·å–ç”¨æˆ·çš„å¯¹è¯å†å²
  async getUserConversations(): Promise<ApiResponse<AIConversation[]>> {
    try {
      const { data: { user } } = await supabase.auth.getUser()
      if (!user) throw new Error('ç”¨æˆ·æœªç™»å½•')

      const { data, error } = await supabase
        .from('ai_conversations')
        .select('*')
        .eq('user_id', user.id)
        .order('updated_at', { ascending: false })

      if (error) throw error
      return { data: data || [] }
    } catch (error: any) {
      return { data: [], error: error.message }
    }
  },

  // å‘é€æ¶ˆæ¯åˆ° AI
  async sendMessage(
    conversationId: string,
    message: string,
    config?: AIAssistantConfig
  ): Promise<ApiResponse<AIMessage>> {
    try {
      // è·å–å¯¹è¯ä¸Šä¸‹æ–‡
      const { data: conversation, error: convError } = await supabase
        .from('ai_conversations')
        .select('*')
        .eq('id', conversationId)
        .single()

      if (convError) throw convError

      // ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
      const userMessage: Omit<AIMessage, 'id'> = {
        conversation_id: conversationId,
        role: 'user',
        content: message,
        timestamp: new Date().toISOString()
      }

      const { error: userMsgError } = await supabase
        .from('ai_messages')
        .insert([userMessage])
        .select()
        .single()

      if (userMsgError) throw userMsgError

      // è°ƒç”¨ AI API è·å–å›å¤
      const aiResponse = await aiService.generateConversationResponse(conversation, message, config)

      // ä¿å­˜ AI å›å¤
      const aiMessage: Omit<AIMessage, 'id'> = {
        conversation_id: conversationId,
        role: 'assistant',
        content: aiResponse,
        timestamp: new Date().toISOString()
      }

      const { data: savedAIMessage, error: aiMsgError } = await supabase
        .from('ai_messages')
        .insert([aiMessage])
        .select()
        .single()

      if (aiMsgError) throw aiMsgError

      // æ›´æ–°å¯¹è¯æ—¶é—´æˆ³
      await supabase
        .from('ai_conversations')
        .update({ updated_at: new Date().toISOString() })
        .eq('id', conversationId)

      return { data: savedAIMessage }
    } catch (error: any) {
      return { data: {} as AIMessage, error: error.message }
    }
  },

  // è·å–å¯¹è¯çš„æ‰€æœ‰æ¶ˆæ¯
  async getConversationMessages(conversationId: string): Promise<ApiResponse<AIMessage[]>> {
    try {
      const { data, error } = await supabase
        .from('ai_messages')
        .select('*')
        .eq('conversation_id', conversationId)
        .order('timestamp', { ascending: true })

      if (error) throw error
      return { data: data || [] }
    } catch (error: any) {
      return { data: [], error: error.message }
    }
  },

  // ğŸš€ è·å–å¯¹è¯çš„æœ€è¿‘æ¶ˆæ¯ï¼ˆåˆ†é¡µåŠ è½½ä¼˜åŒ–ï¼‰
  async getRecentConversationMessages(
    conversationId: string, 
    limit: number = 20
  ): Promise<ApiResponse<AIMessage[]>> {
    try {
      const { data, error } = await supabase
        .from('ai_messages')
        .select('*')
        .eq('conversation_id', conversationId)
        .order('timestamp', { ascending: false }) // é™åºè·å–æœ€æ–°çš„
        .limit(limit)

      if (error) throw error
      
      // ç¿»è½¬é¡ºåºï¼Œè®©æœ€è€çš„æ¶ˆæ¯åœ¨å‰é¢
      const messages = (data || []).reverse()
      return { data: messages }
    } catch (error: any) {
      return { data: [], error: error.message }
    }
  },

  // ğŸš€ è·å–å¯¹è¯çš„æœ€è¿‘æ¶ˆæ¯é¢„è§ˆï¼ˆè¶…å¿«é€ŸåŠ è½½ï¼‰
  async getRecentConversationMessagesPreviews(
    conversationId: string, 
    limit: number = 20
  ): Promise<ApiResponse<AIMessage[]>> {
    try {
      const { data, error } = await supabase
        .from('ai_messages')
        .select(`
          id,
          conversation_id,
          role,
          timestamp,
          content
        `)
        .eq('conversation_id', conversationId)
        .order('timestamp', { ascending: false })
        .limit(limit)

      if (error) throw error
      
      // å¤„ç†æ¶ˆæ¯ï¼šæˆªæ–­é•¿å†…å®¹ä¸ºé¢„è§ˆ
      const processedMessages = (data || []).map(message => ({
        ...message,
        content: message.content.length > 150 
          ? message.content.substring(0, 150) + '...' 
          : message.content,
        isPreview: message.content.length > 150 // æ ‡è®°æ˜¯å¦ä¸ºé¢„è§ˆ
      })).reverse() // ç¿»è½¬é¡ºåº

      return { data: processedMessages as AIMessage[] }
    } catch (error: any) {
      return { data: [], error: error.message }
    }
  },

  // ğŸš€ è·å–æ¶ˆæ¯çš„å®Œæ•´å†…å®¹
  async getMessageFullContent(messageId: string): Promise<ApiResponse<string>> {
    try {
      const { data, error } = await supabase
        .from('ai_messages')
        .select('content')
        .eq('id', messageId)
        .single()

      if (error) throw error
      return { data: data.content }
    } catch (error: any) {
      return { data: '', error: error.message }
    }
  },

  // ğŸš€ è·å–å¯¹è¯çš„æ›´å¤šå†å²æ¶ˆæ¯ï¼ˆå‘å‰åˆ†é¡µï¼‰
  async getMoreConversationMessages(
    conversationId: string,
    beforeTimestamp: string,
    limit: number = 20
  ): Promise<ApiResponse<AIMessage[]>> {
    try {
      const { data, error } = await supabase
        .from('ai_messages')
        .select('*')
        .eq('conversation_id', conversationId)
        .lt('timestamp', beforeTimestamp)
        .order('timestamp', { ascending: false })
        .limit(limit)

      if (error) throw error
      
      // ç¿»è½¬é¡ºåºï¼Œè®©æœ€è€çš„æ¶ˆæ¯åœ¨å‰é¢
      const messages = (data || []).reverse()
      return { data: messages }
    } catch (error: any) {
      return { data: [], error: error.message }
    }
  },

  // åˆ é™¤å¯¹è¯å’Œç›¸å…³æ¶ˆæ¯ - ä¼˜åŒ–ç‰ˆæœ¬
  async deleteConversation(conversationId: string): Promise<ApiResponse<{ success: boolean }>> {
    try {
      const { data: { user } } = await supabase.auth.getUser()
      if (!user) throw new Error('ç”¨æˆ·æœªç™»å½•')

      // ğŸš€ ä¼˜åŒ–ï¼šåˆ©ç”¨CASCADEåˆ é™¤å’ŒRLSç­–ç•¥ï¼Œä¸€æ¬¡æ“ä½œåˆ é™¤å¯¹è¯åŠæ‰€æœ‰ç›¸å…³æ¶ˆæ¯
      // æ•°æ®åº“çš„å¤–é”®çº¦æŸä¼šè‡ªåŠ¨åˆ é™¤ç›¸å…³æ¶ˆæ¯ï¼ŒRLSä¼šç¡®ä¿æƒé™å®‰å…¨
      const { error: conversationError } = await supabase
        .from('ai_conversations')
        .delete()
        .eq('id', conversationId)
        .eq('user_id', user.id) // RLSä¼šç¡®ä¿ç”¨æˆ·åªèƒ½åˆ é™¤è‡ªå·±çš„å¯¹è¯

      if (conversationError) throw conversationError

      return { data: { success: true } }
    } catch (error: any) {
      return { data: { success: false }, error: error.message }
    }
  },

  // åˆ é™¤ç”¨æˆ·çš„æ‰€æœ‰å¯¹è¯ - ä¼˜åŒ–ç‰ˆæœ¬
  async deleteAllConversations(): Promise<ApiResponse<{ success: boolean, deletedCount: number }>> {
    try {
      const { data: { user } } = await supabase.auth.getUser()
      if (!user) throw new Error('ç”¨æˆ·æœªç™»å½•')

      // ğŸš€ ä¼˜åŒ–ï¼šå…ˆè·å–è¦åˆ é™¤çš„å¯¹è¯æ•°é‡ï¼Œç„¶ååˆ©ç”¨CASCADEä¸€æ¬¡æ€§åˆ é™¤
      const { data: conversations, error: countError } = await supabase
        .from('ai_conversations')
        .select('id')
        .eq('user_id', user.id)

      if (countError) throw countError
      
      const deletedCount = conversations?.length || 0

      if (deletedCount === 0) {
        return { data: { success: true, deletedCount: 0 } }
      }

      // ğŸš€ åˆ©ç”¨CASCADEåˆ é™¤ï¼šåˆ é™¤æ‰€æœ‰å¯¹è¯ï¼Œç›¸å…³æ¶ˆæ¯ä¼šè‡ªåŠ¨åˆ é™¤
      const { error: conversationsError } = await supabase
        .from('ai_conversations')
        .delete()
        .eq('user_id', user.id)

      if (conversationsError) throw conversationsError

      return { data: { success: true, deletedCount } }
    } catch (error: any) {
      return { data: { success: false, deletedCount: 0 }, error: error.message }
    }
  }
}

// å¤ä¹ å¡ç‰‡ API
export const reviewCardsApi = {
  // ä¸ºè¯¾ç¨‹ç”Ÿæˆå¤ä¹ å¡ç‰‡
  async generateReviewCards(courseId: string): Promise<ApiResponse<ReviewCard[]>> {
    try {
      // è·å–è¯¾ç¨‹ææ–™å’Œä»»åŠ¡ä¿¡æ¯
      const { data: materials } = await supabase
        .from('course_materials')
        .select('*')
        .eq('course_id', courseId)

      const { data: tasks } = await supabase
        .from('tasks')
        .select('*')
        .eq('course_id', courseId)

      // åˆå¹¶è¯¾ç¨‹å†…å®¹
      const courseContent = {
        materials: materials || [],
        tasks: tasks || []
      }

      // è°ƒç”¨ AI ç”Ÿæˆå¤ä¹ å¡ç‰‡
      const cards = await aiService.generateReviewCards(courseContent)

      // ä¿å­˜åˆ°æ•°æ®åº“
      const cardsWithCourseId = cards.map(card => ({
        ...card,
        course_id: courseId
      }))

      const { data, error } = await supabase
        .from('review_cards')
        .insert(cardsWithCourseId)
        .select()

      if (error) throw error
      return { data: data || [] }
    } catch (error: any) {
      return { data: [], error: error.message }
    }
  },

  // è·å–è¯¾ç¨‹çš„å¤ä¹ å¡ç‰‡
  async getCourseReviewCards(courseId: string): Promise<ApiResponse<ReviewCard[]>> {
    try {
      const { data, error } = await supabase
        .from('review_cards')
        .select('*')
        .eq('course_id', courseId)
        .order('created_at', { ascending: false })

      if (error) throw error
      return { data: data || [] }
    } catch (error: any) {
      return { data: [], error: error.message }
    }
  },

  // æ›´æ–°å¡ç‰‡æŒæ¡ç¨‹åº¦
  async updateCardMastery(cardId: string, masteryLevel: number): Promise<ApiResponse<ReviewCard>> {
    try {
      const { data, error } = await supabase
        .from('review_cards')
        .update({
          mastery_level: masteryLevel,
          last_reviewed: new Date().toISOString()
        })
        .eq('id', cardId)
        .select()
        .single()

      if (error) throw error
      return { data }
    } catch (error: any) {
      return { data: {} as ReviewCard, error: error.message }
    }
  }
}

// å‘¨æŠ¥å‘Š API
export const weeklyReportApi = {
  // ç”Ÿæˆå‘¨æŠ¥å‘Š
  async generateWeeklyReport(weekStart: string, weekEnd: string): Promise<ApiResponse<WeeklyReport>> {
    try {
      const { data: { user } } = await supabase.auth.getUser()
      if (!user) throw new Error('ç”¨æˆ·æœªç™»å½•')

      // è·å–æœ¬å‘¨çš„ä»»åŠ¡æ•°æ®
      const { data: tasks } = await supabase
        .from('tasks')
        .select(`
          *,
          courses!inner(user_id)
        `)
        .eq('courses.user_id', user.id)
        .gte('due_date', weekStart)
        .lte('due_date', weekEnd)

      // è®¡ç®—ç»Ÿè®¡æ•°æ®
      const stats = this.calculateWeeklyStats(tasks || [])

      // ç”Ÿæˆ AI å»ºè®®
      const recommendations = await aiService.generateWeeklyRecommendations(stats, tasks || [])

      // åˆ›å»ºå‘¨æŠ¥å‘Š
      const reportData: Omit<WeeklyReport, 'id' | 'created_at'> = {
        user_id: user.id,
        week_start: weekStart,
        week_end: weekEnd,
        ...stats,
        recommendations
      }

      const { data, error } = await supabase
        .from('weekly_reports')
        .insert([reportData])
        .select()
        .single()

      if (error) throw error
      return { data }
    } catch (error: any) {
      return { data: {} as WeeklyReport, error: error.message }
    }
  },

  // è®¡ç®—å‘¨ç»Ÿè®¡æ•°æ®
  calculateWeeklyStats(tasks: any[]): {
    tasks_completed: number
    total_tasks: number
    completion_rate: number
    study_hours: number
    procrastination_index: number
    focus_score: number
  } {
    const totalTasks = tasks.length
    const completedTasks = tasks.filter(task => task.status === 'completed').length
    const overdueTasks = tasks.filter(task => task.status === 'overdue').length
    const totalStudyHours = tasks.reduce((sum, task) => sum + (task.actual_hours || 0), 0)
    const averageTaskHours = totalTasks > 0 ? totalStudyHours / totalTasks : 0

    return {
      tasks_completed: completedTasks,
      total_tasks: totalTasks,
      completion_rate: totalTasks > 0 ? Math.round((completedTasks / totalTasks) * 100) : 0,
      study_hours: totalStudyHours,
      procrastination_index: totalTasks > 0 ? Math.min(Math.round((overdueTasks / totalTasks) * 10), 10) : 0,
      focus_score: this.calculateFocusScore(completedTasks, totalStudyHours, averageTaskHours)
    }
  },

  // è®¡ç®—ä¸“æ³¨åº¦è¯„åˆ†
  calculateFocusScore(completedTasks: number, totalStudyHours: number, averageTaskHours: number): number {
    if (totalStudyHours === 0 || averageTaskHours === 0) return 0
    
    const efficiency = completedTasks / totalStudyHours
    const expectedEfficiency = 1 / averageTaskHours
    const score = (efficiency / expectedEfficiency) * 100
    
    return Math.min(Math.max(Math.round(score), 0), 100)
  },

  // è·å–ç”¨æˆ·çš„å‘¨æŠ¥å‘Šå†å²
  async getUserWeeklyReports(): Promise<ApiResponse<WeeklyReport[]>> {
    try {
      const { data: { user } } = await supabase.auth.getUser()
      if (!user) throw new Error('ç”¨æˆ·æœªç™»å½•')

      const { data, error } = await supabase
        .from('weekly_reports')
        .select('*')
        .eq('user_id', user.id)
        .order('week_start', { ascending: false })

      if (error) throw error
      return { data: data || [] }
    } catch (error: any) {
      return { data: [], error: error.message }
    }
  }
}

// AI Course Parsing API
export const aiCourseParseApi = {
  // Parse course materials and generate tasks
  async parseCourseMaterials(materials: any[]): Promise<ApiResponse<any>> {
    const courseContent = materials
    try {
      const result = await aiService.parseCourseMaterials(courseContent)
      return { data: result }
    } catch (error: any) {
      return { data: {}, error: error.message }
    }
  }
}

// å¯¼å…¥ supabase å®¢æˆ·ç«¯

